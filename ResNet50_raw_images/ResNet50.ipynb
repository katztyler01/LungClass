{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 23:42:27.693648: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/dtboyes/opt/anaconda3/envs/csb/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/Users/dtboyes/opt/anaconda3/envs/csb/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Model\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, AveragePooling2D, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Data_Entry_2017.csv\")\n",
    "filenames = []\n",
    "directories = []\n",
    "with open(\"../selected_png_list.txt\", \"r\") as fr:\n",
    "    for line in fr.readlines():\n",
    "        start = line.find(\"images_0\")\n",
    "        directory = \"images/\" + line[start:]\n",
    "        filename_reverse = line[::-1]\n",
    "        filename_reverse = filename_reverse[:filename_reverse.find(\"/\")]\n",
    "        filename = filename_reverse[::-1]\n",
    "        filenames.append(filename[:-1])\n",
    "        directories.append(directory)\n",
    "data = data[data[\"Image Index\"].isin(filenames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    if row[\"Finding Labels\"].find(\"|\") != -1:\n",
    "        data.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "classifications = np.unique(data.loc[:,\"Finding Labels\"])\n",
    "print(len(classifications))\n",
    "data.to_csv(\"full_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atelectasis 377\n",
      "Cardiomegaly 82\n",
      "Consolidation 102\n",
      "Edema 63\n",
      "Effusion 321\n",
      "Emphysema 71\n",
      "Fibrosis 56\n",
      "Hernia 9\n",
      "Infiltration 807\n",
      "Mass 176\n",
      "No Finding 5210\n",
      "Nodule 214\n",
      "Pleural_Thickening 118\n",
      "Pneumonia 28\n",
      "Pneumothorax 202\n"
     ]
    }
   ],
   "source": [
    "train_full_set = []\n",
    "test_full_set = []\n",
    "data = pd.read_csv(\"full_data.csv\")\n",
    "for classification in classifications:\n",
    "    class_filter = data[data[\"Finding Labels\"] == classification]\n",
    "    print(classification, len(class_filter))\n",
    "    indices_len = len(class_filter)\n",
    "    if indices_len > 400:\n",
    "        indices_len = 400\n",
    "    train_set_size = math.floor(0.8 * indices_len)\n",
    "    permutation = np.random.permutation(np.arange(0,indices_len))\n",
    "    permutation = [int(x) for x in permutation]\n",
    "    \n",
    "    train_filenames = class_filter.iloc[permutation[:train_set_size], 1]\n",
    "    test_filenames = class_filter.iloc[permutation[train_set_size:], 1]\n",
    "\n",
    "    for filename in train_filenames:\n",
    "        train_full_set.append(filename)\n",
    "    for filename in test_filenames:\n",
    "        test_full_set.append(filename)\n",
    "\n",
    "train_data = data[data[\"Image Index\"].isin(train_full_set)]\n",
    "test_data = data[data[\"Image Index\"].isin(test_full_set)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet50 model on Cardiomegaly\n",
      "['Cardiomegaly' 'No Finding']\n",
      "['Atelectasis' 'Cardiomegaly' 'Consolidation' 'Edema' 'Effusion'\n",
      " 'Emphysema' 'Fibrosis' 'Hernia' 'Infiltration' 'Mass' 'No Finding'\n",
      " 'Nodule' 'Pleural_Thickening' 'Pneumonia' 'Pneumothorax']\n",
      "Found 385 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 100s 3s/step - loss: 0.5366 - accuracy: 0.7351 - precision_25: 0.8385 - recall_25: 0.8438 - f1_score: 0.9078 - auc_25: 0.5922\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 82s 3s/step - loss: 0.1108 - accuracy: 0.9740 - precision_25: 0.9755 - recall_25: 0.9937 - f1_score: 0.9078 - auc_25: 0.9894\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 71s 3s/step - loss: 0.0260 - accuracy: 0.9974 - precision_25: 1.0000 - recall_25: 0.9969 - f1_score: 0.9078 - auc_25: 1.0000\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 70s 3s/step - loss: 0.0079 - accuracy: 1.0000 - precision_25: 1.0000 - recall_25: 1.0000 - f1_score: 0.9078 - auc_25: 1.0000\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 69s 3s/step - loss: 0.0047 - accuracy: 1.0000 - precision_25: 1.0000 - recall_25: 1.0000 - f1_score: 0.9078 - auc_25: 1.0000\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 69s 3s/step - loss: 0.0036 - accuracy: 1.0000 - precision_25: 1.0000 - recall_25: 1.0000 - f1_score: 0.9078 - auc_25: 1.0000\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 68s 3s/step - loss: 0.0013 - accuracy: 1.0000 - precision_25: 1.0000 - recall_25: 1.0000 - f1_score: 0.9078 - auc_25: 1.0000\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 70s 3s/step - loss: 0.0016 - accuracy: 1.0000 - precision_25: 1.0000 - recall_25: 1.0000 - f1_score: 0.9078 - auc_25: 1.0000\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0012 - accuracy: 1.0000 - precision_25: 1.0000 - recall_25: 1.0000 - f1_score: 0.9078 - auc_25: 1.0000\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 69s 3s/step - loss: 0.0135 - accuracy: 0.9974 - precision_25: 0.9969 - recall_25: 1.0000 - f1_score: 0.9078 - auc_25: 0.9999\n",
      "Testing ResNet50 model on Cardiomegaly\n",
      "Found 97 validated image filenames belonging to 2 classes.\n",
      "7/7 [==============================] - 5s 541ms/step\n",
      "7/7 [==============================] - 5s 555ms/step - loss: 0.5486 - accuracy: 0.8247 - precision_25: 0.8247 - recall_25: 1.0000 - f1_score: 0.9040 - auc_25: 0.5463\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "classifications_observed = classifications[classifications != \"No Finding\"]\n",
    "classifications_observed = [\"Cardiomegaly\"]\n",
    "model_predictions = []\n",
    "histories = []\n",
    "for classification in classifications_observed:\n",
    "        # assemble ResNet50 model\n",
    "        base_model = ResNet50(include_top=False, \n",
    "                                    classes=1,\n",
    "                                    input_shape=(1024,1024,3))\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = LeakyReLU(alpha = 0.4)(x)\n",
    "        predictions = Dense(1, activation='sigmoid')(x)\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall(), F1Score(num_classes=1, average = \"weighted\"), AUC(curve = \"ROC\")])\n",
    "\n",
    "        print(f\"Training ResNet50 model on {classification}\")\n",
    "        possible_classes = [classification, \"No Finding\"]\n",
    "        \n",
    "        train_data_subset = train_data[train_data[\"Finding Labels\"].isin(possible_classes)]\n",
    "        print(np.unique(train_data_subset.loc[:,\"Finding Labels\"]))\n",
    "\n",
    "        print(np.unique(train_data.loc[:,\"Finding Labels\"]))\n",
    "        train_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function=preprocess_input)\n",
    "        train_generator = train_datagen.flow_from_dataframe(\n",
    "                train_data_subset,\n",
    "                x_col = \"Image Index\",\n",
    "                y_col = \"Finding Labels\",\n",
    "                directory = \"images\",\n",
    "                target_size=(224,224),\n",
    "                batch_size=16,\n",
    "                class_mode='binary',\n",
    "                shuffle=True)\n",
    "\n",
    "\n",
    "        history = model.fit(\n",
    "                train_generator,\n",
    "                steps_per_epoch=len(train_generator),\n",
    "                epochs=10,\n",
    "                verbose=1)\n",
    "        \n",
    "        \n",
    "        print(f\"Testing ResNet50 model on {classification}\")\n",
    "        test_data_subset = test_data[test_data[\"Finding Labels\"].isin(possible_classes)]\n",
    "        # test_data_y_cols = list(test_data_subset.columns[16:])\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255,preprocessing_function=preprocess_input)\n",
    "        test_generator = test_datagen.flow_from_dataframe(\n",
    "                test_data_subset,\n",
    "                x_col = \"Image Index\",\n",
    "                y_col = \"Finding Labels\",\n",
    "                directory = \"images\",\n",
    "                target_size=(224,224),\n",
    "                batch_size=16,\n",
    "                class_mode='binary',\n",
    "                shuffle=True)\n",
    "        \n",
    "        histories.append(history)\n",
    "        model_predictions.append(model.predict(test_generator))\n",
    "        model.evaluate(test_generator)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
